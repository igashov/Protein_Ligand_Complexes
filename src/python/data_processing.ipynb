{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Считываем данные (refined dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import array, struct, sys, os, tqdm\n",
    "import numpy as np\n",
    "\n",
    "def read_binaries(path_binfiles):\n",
    "    result = {}\n",
    "    #cnt = 0\n",
    "    for binfile in tqdm.tqdm(os.listdir(path_binfiles)):\n",
    "        if (binfile.split('.')[1] != 'bin'):\n",
    "            continue\n",
    "        pdbcode = binfile.split('.')[0]                     # name of file (pdbcode)\n",
    "        F = open('{0}/{1}'.format(path_binfiles, binfile), 'rb')\n",
    "        n_decoys = struct.unpack('i', F.read(4))[0]         # number of decoys (=19 for this dataset)\n",
    "        dimension = struct.unpack('i', F.read(4))[0]        # data dimensionality (23 protein types x 40 ligand types x 7 bins for this dataset)\n",
    "        res = []\n",
    "        for i in range(n_decoys):\n",
    "            label = struct.unpack('d', F.read(8))[0]        # label (1 for native, -1 for non-native)\n",
    "            data = array.array('d')                         \n",
    "            data.fromfile(F, dimension)                     # feature vector (histograms, can be represented as a 23x40x7 matrix) \n",
    "            res.append([label, data])\n",
    "        result[pdbcode] = res\n",
    "        F.close()\n",
    "        #if cnt == 13080:\n",
    "        #    break\n",
    "        #cnt += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13090/13090 [01:40<00:00, 129.63it/s]\n"
     ]
    }
   ],
   "source": [
    "result = read_binaries('../../../../../basic_experiment/general-no2013_t14_t3_l7.0_g1.0_r1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../../../../../basic_experiment/affinity_data_refined.csv', 'r') as f:\n",
    "    data = f.read().split('\\n')\n",
    "    data = data[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    {'name': d.split(',')[0], 'value': d.split(',')[1], 'type': d.split(',')[3]}\n",
    "    for d in data\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Kd_values = []\n",
    "Ki_values = []\n",
    "for d in datasets:\n",
    "    if d['type'] == 'Kd':\n",
    "        Kd_values.append(d)\n",
    "    else:\n",
    "        Ki_values.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Kd_data = []\n",
    "for item in Kd_values:\n",
    "    Kd_data.append([item['value']] + result[item['name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ki_data = []\n",
    "for item in Ki_values:\n",
    "    if item['name'] != '966c':\n",
    "        Ki_data.append([item['value']] + result[item['name']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 этап. Предсказание свободной энергии.\n",
    "Для обучения рассматриваем для каждого комплекса только его нативную позу (т.к. только для них известны значения свободной энергии).\n",
    "\n",
    "Берем все нативные позы со значениями Ki (Ki_data) из refined dataset.\n",
    "\n",
    "Предсказываем значение Ki."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа с данными:\n",
    "\n",
    "    1) Разделение данных на test и train и выделение аффинных данных (X_nat_train)\n",
    "    \n",
    "    2) Замена переменных\n",
    "    \n",
    "    3) Запись в файл нового вектора X (для работы в liblinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from math import log, exp\n",
    "from scipy.linalg import sqrtm, inv, norm\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.4665520191192627 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "data = Ki_data\n",
    "train = data[:int(len(data) * 0.6)]\n",
    "test = data[int(len(data) * 0.6):]\n",
    "\n",
    "# Матрица признаков (для которых аффинности известны)\n",
    "X_nat_train = np.matrix([\n",
    "    t[1][1]\n",
    "    for t in train\n",
    "]).T\n",
    "\n",
    "# Столбец значений свободной энергии\n",
    "s_train = np.matrix([\n",
    "    float(t[0])\n",
    "    for t in train\n",
    "]).T\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6440, 1245)\n",
      "(1245, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_nat_train.shape)\n",
    "print(s_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 19.268756866455078 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "X_train = []\n",
    "for t in train:\n",
    "    for pose in t[1:]:\n",
    "        X_train.append(pose[1])\n",
    "        \n",
    "X_train = np.matrix(X_train).T\n",
    "\n",
    "y_train = []\n",
    "for t in train:\n",
    "    for pose in t[1:]:\n",
    "        y_train.append(pose[0])\n",
    "\n",
    "y_train = np.matrix(y_train).T\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 14.379429817199707 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "X_test = []\n",
    "for t in test:\n",
    "    for pose in t[1:]:\n",
    "        X_test.append(pose[1])\n",
    "        \n",
    "X_test = np.matrix(X_test).T\n",
    "\n",
    "y_test = []\n",
    "for t in test:\n",
    "    for pose in t[1:]:\n",
    "        y_test.append(pose[0])\n",
    "\n",
    "y_test = np.matrix(y_test).T\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6440, 23655)\n",
      "(23655, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 299.31849813461304 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Замена переменных\n",
    "start_time = time.time()\n",
    "Cr = 100 # Коэффициент регуляризации\n",
    "XXT = X_nat_train @ X_nat_train.T\n",
    "I = np.identity(XXT.shape[0])\n",
    "A = np.real(sqrtm(0.5 * I + Cr * XXT))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 13.844375133514404 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "A_inv = inv(A)\n",
    "B = Cr * A_inv @ X_nat_train @ s_train\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6440, 6440)\n",
      "(6440, 1)\n"
     ]
    }
   ],
   "source": [
    "print(A.shape)\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменяем матрицу $X$ на $(A^{-1})^{\\text{T}}X$ и записываем ее вместе с вектором $y$ в файл, чтобы подать этот файл в liblinear.\n",
    "А также вектор постоянных слагаемых внутри функции потерь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23655, 6440)\n"
     ]
    }
   ],
   "source": [
    "newX = (A_inv.T @ X_train).T\n",
    "print(newX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23655/23655 [13:32<00:00, 29.13it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"ki_train\", \"w\") as f:\n",
    "    for i in tqdm.tqdm(range(newX.shape[0])):\n",
    "        y_i = (\"+1 \" if y_train[i] == 1 else \"-1 \")\n",
    "        f.write(y_i)\n",
    "        for j in range(newX.shape[1]):\n",
    "            f.write(str(j + 1) + \":\" + str(newX[i,j]) + \" \")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23655, 1)\n"
     ]
    }
   ],
   "source": [
    "constant = np.multiply(y_train, ((A_inv @ B).T @ X_train).T)\n",
    "print(constant.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.619652833637915"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(constant[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23655/23655 [00:00<00:00, 39954.73it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"ki_train_constant\", \"w\") as f:\n",
    "    for i in tqdm.tqdm(range(constant.shape[0])):\n",
    "        f.write(str(float(constant[i])) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовые файлы (проверка правильно угаданных нативных поз)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23655, 6440)\n"
     ]
    }
   ],
   "source": [
    "newX_test = (A_inv.T @ X_test).T\n",
    "print(newX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1662/1662 [00:57<00:00, 28.86it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"ki_test\", \"w\") as f:\n",
    "    for i in tqdm.tqdm(range(newX_test.shape[0])):\n",
    "        y_i = (\"+1 \" if y_test[i] == 1 else \"-1 \")\n",
    "        f.write(y_i)\n",
    "        for j in range(newX_test.shape[1]):\n",
    "            f.write(str(j + 1) + \":\" + str(newX_test[i,j]) + \" \")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим модель в liblinear, достаем вектор $w$ из файла .model и тестируем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../ki_train.model\", \"r\") as f:\n",
    "    data = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newW = np.array(data[6:-1], dtype=float).reshape((6440, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = A_inv @ (newW + B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"ki_w.txt\", w.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Матрица признаков (для которых аффинности известны)\n",
    "X_test = np.matrix([\n",
    "    t[1][1]\n",
    "    for t in test\n",
    "]).T\n",
    "\n",
    "# Столбец значений свободной энергии\n",
    "s_test = np.matrix([\n",
    "    float(t[0])\n",
    "    for t in test\n",
    "]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman:  SpearmanrResult(correlation=0.64238494002903612, pvalue=6.9057871865105226e-98)\n",
      "Pearson:  (0.62790831694860949, 2.5052835343899646e-92)\n",
      "R2:  -0.56026556888\n",
      "MSE:  6.99550820623\n"
     ]
    }
   ],
   "source": [
    "prediction = w.T @ X_test\n",
    "print(\"Spearman: \", spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"Pearson: \", pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"R2: \", r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"MSE: \", mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman:  SpearmanrResult(correlation=0.69166226720519497, pvalue=2.7519435180374767e-119)\n",
      "Pearson:  (0.68399876227528322, 1.1131347687760896e-115)\n",
      "R2:  0.349571970825\n",
      "MSE:  2.91621805057\n"
     ]
    }
   ],
   "source": [
    "prediction = w.T @ X_test\n",
    "print(\"Spearman: \", spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"Pearson: \", pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"R2: \", r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"MSE: \", mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman:  SpearmanrResult(correlation=0.69015191946932408, pvalue=1.4434995449354607e-118)\n",
      "Pearson:  (0.68219302714172125, 7.5909374048635784e-115)\n",
      "R2:  0.343886262877\n",
      "MSE:  2.9417101318\n"
     ]
    }
   ],
   "source": [
    "prediction = w.T @ X_test\n",
    "print(\"Spearman: \", spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"Pearson: \", pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"R2: \", r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"MSE: \", mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman:  SpearmanrResult(correlation=0.68356234628229917, pvalue=1.7725783590839373e-115)\n",
      "Pearson:  (0.67049209677989263, 1.3800783330340288e-109)\n",
      "R2:  -0.146462513968\n",
      "MSE:  5.14020695231\n"
     ]
    }
   ],
   "source": [
    "prediction = w.T @ X_test\n",
    "print(\"Spearman: \", spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"Pearson: \", pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"R2: \", r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"MSE: \", mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman:  SpearmanrResult(correlation=0.69166226720519497, pvalue=2.7519435180374767e-119)\n",
      "Pearson:  (0.68399876227528322, 1.1131347687760896e-115)\n",
      "R2:  0.349571970825\n",
      "MSE:  2.91621805057\n"
     ]
    }
   ],
   "source": [
    "#L2R_L1LOSS_SVC_DUAL\n",
    "prediction = w.T @ X_test\n",
    "print(\"Spearman: \", spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"Pearson: \", pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"R2: \", r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"MSE: \", mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman:  SpearmanrResult(correlation=0.69015191946932408, pvalue=1.4434995449354607e-118)\n",
      "Pearson:  (0.68219302714172125, 7.5909374048635784e-115)\n",
      "R2:  0.343886262877\n",
      "MSE:  2.9417101318\n"
     ]
    }
   ],
   "source": [
    "# L2_LR с добавкой Constant\n",
    "prediction = w.T @ X_test\n",
    "print(\"Spearman: \", spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"Pearson: \", pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"R2: \", r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"MSE: \", mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.69015191946932408, pvalue=1.4434995449354607e-118)\n",
      "(0.68219302714172125, 7.5909374048635784e-115)\n",
      "0.343886262877\n",
      "2.9417101318\n"
     ]
    }
   ],
   "source": [
    "# L2_LR с добавкой Constant\n",
    "prediction = w.T @ X_test\n",
    "print(spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.69322426613187826, pvalue=4.9040465422768512e-120)\n",
      "(0.68575165540911154, 1.7036531159905999e-116)\n",
      "0.350186214271\n",
      "2.91346406744\n"
     ]
    }
   ],
   "source": [
    "# L2_LOSS_SVC_DUAL\n",
    "prediction = w.T @ X_test\n",
    "print(spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.68356234628229917, pvalue=1.7725783590839373e-115)\n",
      "(0.67049209677989263, 1.3800783330340288e-109)\n",
      "-0.146462513968\n",
      "5.14020695231\n"
     ]
    }
   ],
   "source": [
    "# Тренинговая аффинная выборка и Cr = 100 (вместо 10000), C = 1024\n",
    "prediction = w.T @ X_test\n",
    "print(spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.62014223685389513, pvalue=2.6774230060625381e-133)\n",
      "(0.60320970317061684, 2.4116978508802566e-124)\n",
      "-0.209361431428\n",
      "5.41602792232\n"
     ]
    }
   ],
   "source": [
    "# Тренинговая аффинная выборка и Cr = 10000 (вместо 100), C = 1024\n",
    "prediction = w.T @ X_test_reg\n",
    "print(spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.78110546631570565, pvalue=1.0389205936255559e-256)\n",
      "(0.77570934211099696, 6.0031501273757858e-251)\n",
      "0.327181243734\n",
      "3.01316469659\n"
     ]
    }
   ],
   "source": [
    "# Добавил полную аффинную выборку и Cr = 100 (вместо 10), C = 1024\n",
    "prediction = w.T @ X_test_reg\n",
    "print(spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.68905982191288717, pvalue=3.597549765965038e-176)\n",
      "(0.67739176428319892, 4.3851607724117059e-168)\n",
      "-0.233452411741\n",
      "5.52391744043\n"
     ]
    }
   ],
   "source": [
    "# Добавил полную аффинную выборку и Cr = 5 (вместо 0.5), C = 1024\n",
    "prediction = w.T @ X_test_reg\n",
    "print(spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.59782292604876919, pvalue=1.3171390817460266e-121)\n",
      "(0.5853307218911773, 1.8685088214099835e-115)\n",
      "-1.06153063991\n",
      "9.23239919705\n"
     ]
    }
   ],
   "source": [
    "# Аффинная выборка только из тренинговой выборки, Cr = 0.5, C = 1024\n",
    "prediction = w.T @ X_test_reg\n",
    "print(spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_labels = newW.T @ newX_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_labels = pred_labels.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl = [\n",
    "    1 if p > 0 else -1\n",
    "    for p in pred_labels\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5258724428399518"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(831):\n",
    "    flag = True\n",
    "    for j in range(19):\n",
    "        index = i * 19 + j\n",
    "        if (pl[index] != y_test[index]):\n",
    "            flag = False\n",
    "    if flag is True:\n",
    "        cnt += 1\n",
    "cnt / 831"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "831.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pl) / 19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASF-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, glob, tqdm, struct, array\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr as pearsonr\n",
    "import getpass \n",
    "username = getpass.getuser()\n",
    "PATH_data = '/Users/igasov_ilya/Desktop/6semestr/Article/basic_experiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "affinities195 = {}\n",
    "for ki in Ki_values[int(len(Ki_data) * 0.6):]:\n",
    "    affinities195[ki['name']] = float(ki['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 832/832 [00:05<00:00, 144.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# load data for the docking test \n",
    "PATH_CASF = '{0}/'.format(PATH_data)\n",
    "PATH_docking_d = '{0}general-no2013_t14_t3_l7.0_g1.0_r1.0/'.format(PATH_CASF)\n",
    "dock_binaries = affinities195.keys()\n",
    "recs195 = set([ele[:4] for ele in dock_binaries])\n",
    "docking_dict = {rec: [] for rec in recs195}\n",
    "docking_dict_qual = {}\n",
    "docking_scores = {}\n",
    "native_scores = {}\n",
    "# мой скоринг-вектор:\n",
    "#w = np.loadtxt('/home/maria/data/pdbbind/2016/protlig_stat/gen_t14_t3_l7.0_g1.0_r1.0/gen_t14_t3_l7.0_g1.0_r1.0_c20000_f500.txt')[1:]\n",
    "w = np.loadtxt(\"tests/ki_w.txt\")   \n",
    "# flexibilities = {flex.split(',')[0]: float(flex.split(',')[1]) for flex in np.loadtxt('{0}casf-2013.flexibilities.csv'.format(PATH_CASF), dtype=np.str)}\n",
    "\n",
    "# for irec, rec in enumerate(recs195):\n",
    "for rec in tqdm.tqdm(recs195):\n",
    "    # !!! uncomment solvent-related stuff if you need it !!!\n",
    "    data = []\n",
    "    F = open('{0}{1}.bin'.format(PATH_docking_d, rec), 'rb')\n",
    "    n_decoys = struct.unpack('i', F.read(4))[0]         \n",
    "    dimension = struct.unpack('i', F.read(4))[0]\n",
    "    # F_sol = open('{0}{1}.bin.solvent'.format(PATH_docking_d, rec), 'rb')\n",
    "    # n_decoys_sol = struct.unpack('i', F_sol.read(4))[0]\n",
    "    # dimension_sol = struct.unpack('i', F_sol.read(4))[0]\n",
    "    docking_scores[rec] = []\n",
    "    docking_dict_qual[rec] = []\n",
    "    for i in range(n_decoys):\n",
    "        #rms = struct.unpack('d', F.read(8))[0]\n",
    "        label = struct.unpack('d', F.read(8))[0]        # label (0 for native, 1 for RMSD < 1, 2 for RMSD < 2; 3 for RMSD < 3, -1 for RMSD > 3)\n",
    "        data = array.array('d')\n",
    "        data.fromfile(F, dimension)                     # feature vector: histograms (can be represented as a 23x40x7 matrix)\n",
    "        # data_sol = array.array('d')\n",
    "        # data_sol.fromfile(F_sol, dimension_sol)\n",
    "        # data = list(data) + list(data_sol) + [flexibilities[rec]]\n",
    "        score = np.sum(w * data)                          # !!! compute score with your scoring vector here !!!\n",
    "        docking_scores[rec].append(score)\n",
    "        if not label:\n",
    "            native_scores[rec] = score\n",
    "        docking_dict_qual[rec].append(label)\n",
    "    F.close()\n",
    "    # F_sol.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_docking_test():\n",
    "    tq0, tq1, tq2, tq3 = [0]*3, [0]*3, [0]*3, [0]*3 \n",
    "    \n",
    "    tnq1, tnq2, tnq3 = [0]*3, [0]*3, [0]*3   # счетчики, не учитывющие нативные позы\n",
    "    \n",
    "    nPerc1, nPerc5, nPerc10 = 0, 0, 0\n",
    "    \n",
    "    for i_r, rec in enumerate(recs195):\n",
    "        cur_best_res = docking_scores[rec]\n",
    "        idx_sorted = np.argsort(cur_best_res)[::-1]\n",
    "        q0, q1, q2, q3 = 0, 0, 0, 0\n",
    "        nq1, nq2, nq3 = 0, 0, 0\n",
    "        for k in range(3):\n",
    "            if docking_dict_qual[rec][idx_sorted[k]] == 0:\n",
    "                q0 = 1\n",
    "                q1 = 1\n",
    "                q2 = 1\n",
    "                q3 = 1\n",
    "            if docking_dict_qual[rec][idx_sorted[k]] == 1:\n",
    "                q1 = 1\n",
    "                q2 = 1\n",
    "                q3 = 1\n",
    "            if docking_dict_qual[rec][idx_sorted[k]] == 2:\n",
    "                q2 = 1\n",
    "                q3 = 1\n",
    "            if docking_dict_qual[rec][idx_sorted[k]] == 3:\n",
    "                q3 = 1\n",
    "            tq0[k] += q0\n",
    "            tq1[k] += q1\n",
    "            tq2[k] += q2\n",
    "            tq3[k] += q3\n",
    "        j, k = 0, 0\n",
    "        for j in range(5):\n",
    "            if k >= 3:\n",
    "                break\n",
    "            if docking_dict_qual[rec][idx_sorted[j]] == 0:\n",
    "                continue\n",
    "            if docking_dict_qual[rec][idx_sorted[j]] == 1:\n",
    "                nq1 = 1\n",
    "                nq2 = 1\n",
    "                nq3 = 1\n",
    "            if docking_dict_qual[rec][idx_sorted[j]] == 2:\n",
    "                nq2 = 1\n",
    "                nq3 = 1\n",
    "            if docking_dict_qual[rec][idx_sorted[j]] == 3:\n",
    "                nq3 = 1\n",
    "            tnq1[k] += nq1\n",
    "            tnq2[k] += nq2\n",
    "            tnq3[k] += nq3\n",
    "            k += 1\n",
    "        \n",
    "    for k in range(3):\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "        print(\"Top{0:2d}_Native: {1:<5d} Top{0:2d}_Quality_1: {2:<5d} Top{0:2d}_Quality_2: {3:<5d} Top{0:2d}_Quality_3: {4:<5d} \".format(k+1, tq0[k], tq1[k], tq2[k], tq3[k]), end=' ')\n",
    "        print(\"Natives excluded Top{0:2d}_Quality_1: {1:<5d} Top{0:2d}_Quality_2: {2:<5d} Top{0:2d}_Quality_3: {3:<5d}\".format(k+1, tnq1[k], tnq2[k], tnq3[k]))\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "    for k in range(3):\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "        print(\"Top{0:2d}_Native: {1:<7.3f} Top{0:2d}_Quality_1: {2:<7.3f} Top{0:2d}_Quality_2: {3:<7.3f} Top{0:2d}_Quality_3: {4:<7.3f} \".format(k+1, tq0[k]/195, tq1[k]/195, tq2[k]/195, tq3[k]/195), end=' ')\n",
    "        print(\"Natives excluded Top{0:2d}_Quality_1: {1:<7.3f} Top{0:2d}_Quality_2: {2:<7.3f} Top{0:2d}_Quality_3: {3:<7.3f}\".format(k+1, tnq1[k]/195, tnq2[k]/195, tnq3[k]/195))\n",
    "        print(\"-----------------------------------------------------------------------\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_scoring_test():\n",
    "    # Тут просто считаем корреляцию\n",
    "    to_compare = []\n",
    "    for com in affinities195.keys():\n",
    "        to_compare.append([native_scores[com], affinities195[com]])\n",
    "    to_compare = np.array(to_compare)\n",
    "    print(pearsonr(to_compare[:, 0], to_compare[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Top 1_Native: 0     Top 1_Quality_1: 128   Top 1_Quality_2: 128   Top 1_Quality_3: 128    Natives excluded Top 1_Quality_1: 128   Top 1_Quality_2: 128   Top 1_Quality_3: 128  \n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "Top 2_Native: 0     Top 2_Quality_1: 259   Top 2_Quality_2: 259   Top 2_Quality_3: 259    Natives excluded Top 2_Quality_1: 259   Top 2_Quality_2: 259   Top 2_Quality_3: 259  \n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "Top 3_Native: 0     Top 3_Quality_1: 388   Top 3_Quality_2: 388   Top 3_Quality_3: 388    Natives excluded Top 3_Quality_1: 388   Top 3_Quality_2: 388   Top 3_Quality_3: 388  \n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "Top 1_Native: 0.000   Top 1_Quality_1: 0.656   Top 1_Quality_2: 0.656   Top 1_Quality_3: 0.656    Natives excluded Top 1_Quality_1: 0.656   Top 1_Quality_2: 0.656   Top 1_Quality_3: 0.656  \n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "Top 2_Native: 0.000   Top 2_Quality_1: 1.328   Top 2_Quality_2: 1.328   Top 2_Quality_3: 1.328    Natives excluded Top 2_Quality_1: 1.328   Top 2_Quality_2: 1.328   Top 2_Quality_3: 1.328  \n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      "Top 3_Native: 0.000   Top 3_Quality_1: 1.990   Top 3_Quality_2: 1.990   Top 3_Quality_3: 1.990    Natives excluded Top 3_Quality_1: 1.990   Top 3_Quality_2: 1.990   Top 3_Quality_3: 1.990  \n",
      "-----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'4cws'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-0eea2f37f27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrun_docking_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_scoring_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-6c72c06ee473>\u001b[0m in \u001b[0;36mrun_scoring_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mto_compare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maffinities195\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mto_compare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnative_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffinities195\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mto_compare\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_compare\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_compare\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_compare\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '4cws'"
     ]
    }
   ],
   "source": [
    "run_docking_test()\n",
    "run_scoring_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказываем Kd + Ki вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for item in datasets:\n",
    "    if item['name'] != '966c':\n",
    "        data.append([item['value']] + result[item['name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4.490758895874023 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train = data[:int(len(data) * 0.6)]\n",
    "test = data[int(len(data) * 0.6):]\n",
    "\n",
    "# Матрица признаков (для которых аффинности известны)\n",
    "X_nat_train = np.matrix([\n",
    "    t[1][1]\n",
    "    for t in train\n",
    "]).T\n",
    "\n",
    "# Столбец значений свободной энергии\n",
    "s_train = np.matrix([\n",
    "    float(t[0])\n",
    "    for t in train\n",
    "]).T\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 37.7387900352478 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "X_train = []\n",
    "for t in train:\n",
    "    for pose in t[1:]:\n",
    "        X_train.append(pose[1])\n",
    "        \n",
    "X_train = np.matrix(X_train).T\n",
    "\n",
    "y_train = []\n",
    "for t in train:\n",
    "    for pose in t[1:]:\n",
    "        y_train.append(pose[0])\n",
    "\n",
    "y_train = np.matrix(y_train).T\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6440, 2319)\n",
      "(2319, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_nat_train.shape)\n",
    "print(s_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6440, 44061)\n",
      "(44061, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 255.46882796287537 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Замена переменных\n",
    "start_time = time.time()\n",
    "Cr = 100 # Коэффициент регуляризации\n",
    "XXT = X_nat_train @ X_nat_train.T\n",
    "I = np.identity(XXT.shape[0])\n",
    "A = np.real(sqrtm(0.5 * I + Cr * XXT))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 17.51669406890869 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "A_inv = inv(A)\n",
    "B = Cr * A_inv @ X_nat_train @ s_train\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6440, 6440)\n",
      "(6440, 1)\n"
     ]
    }
   ],
   "source": [
    "print(A.shape)\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44061, 6440)\n"
     ]
    }
   ],
   "source": [
    "newX = (A_inv.T @ X_train).T\n",
    "print(newX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44061/44061 [22:41<00:00, 32.37it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"kd_ki_train\", \"w\") as f:\n",
    "    for i in tqdm.tqdm(range(newX.shape[0])):\n",
    "        y_i = (\"+1 \" if y_train[i] == 1 else \"-1 \")\n",
    "        f.write(y_i)\n",
    "        for j in range(newX.shape[1]):\n",
    "            f.write(str(j + 1) + \":\" + str(newX[i,j]) + \" \")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44061, 1)\n"
     ]
    }
   ],
   "source": [
    "constant = np.multiply(y_train, ((A_inv @ B).T @ X_train).T)\n",
    "print(constant.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.379578518520287"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(constant[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44061/44061 [00:00<00:00, 60629.61it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"kd_ki_train_constant\", \"w\") as f:\n",
    "    for i in tqdm.tqdm(range(constant.shape[0])):\n",
    "        f.write(str(float(constant[i])) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестовые файлы (проверка правильно угаданных нативных поз)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newX_test = (A_inv.T @ X_test).T\n",
    "print(newX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"ki_test\", \"w\") as f:\n",
    "    for i in tqdm.tqdm(range(newX_test.shape[0])):\n",
    "        y_i = (\"+1 \" if y_test[i] == 1 else \"-1 \")\n",
    "        f.write(y_i)\n",
    "        for j in range(newX_test.shape[1]):\n",
    "            f.write(str(j + 1) + \":\" + str(newX_test[i,j]) + \" \")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим модель в liblinear, достаем вектор $w$ из файла .model и тестируем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../kd_ki_train.model\", \"r\") as f:\n",
    "    data = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newW = np.array(data[6:-1], dtype=float).reshape((6440, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = A_inv @ (newW + B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"kd_ki_w.txt\", w.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Матрица признаков (для которых аффинности известны)\n",
    "X_test = np.matrix([\n",
    "    t[1][1]\n",
    "    for t in test\n",
    "]).T\n",
    "\n",
    "# Столбец значений свободной энергии\n",
    "s_test = np.matrix([\n",
    "    float(t[0])\n",
    "    for t in test\n",
    "]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman:  SpearmanrResult(correlation=0.66066142353770696, pvalue=1.1705380687619865e-194)\n",
      "Pearson:  (0.65599302356610145, 5.1407873073395082e-191)\n",
      "R2:  0.275077434998\n",
      "MSE:  2.96949059399\n"
     ]
    }
   ],
   "source": [
    "prediction = w.T @ X_test\n",
    "print(\"Spearman: \", spearmanr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"Pearson: \", pearsonr(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"R2: \", r2_score(np.array(s_test.T)[0], np.array(prediction)[0]))\n",
    "print(\"MSE: \", mean_squared_error(np.array(s_test.T)[0], np.array(prediction)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
